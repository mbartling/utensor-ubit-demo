// Auto generated by utensor-cli

#include "uTensor/ops/NnOps.hpp"
#include "uTensor/ops/MathOps.hpp"
#include "mnist_for_uTensor_weight.hpp"
#include "uTensor/core/context.hpp"
#include "mnist_for_uTensor.hpp"
#include "uTensor/ops/ArrayOps.hpp"
#include "uTensor/core/tensor.hpp"
#include "uTensor/ops/MatrixOps.hpp"


void get_mnist_for_uTensor_ctx(Context& ctx) {
    {    
        ctx.add(new BinaryTensor<float>({1,784}, inline_sref_Const_1_0), 
                sref_Const_1_0, 
                2);
    }
    {    
        ctx.add(new BinaryTensor<int>({1}, inline_sref_model_mul_eightbit_Const_1__port__0_reshape_dims_0), 
                sref_model_mul_eightbit_Const_1__port__0_reshape_dims_0, 
                1);
    }
    {
        ctx.add(new RamTensor<float>(), sref_model_mul_eightbit_Const_1__port__0_reshape_0, 2);
        ctx.push(new ReshapeOp(), 
                { sref_Const_1_0, sref_model_mul_eightbit_Const_1__port__0_reshape_dims_0 },
                { sref_model_mul_eightbit_Const_1__port__0_reshape_0 });
        ctx.eval();
    }
    {    
        ctx.add(new BinaryTensor<int>({1}, inline_sref_model_mul_eightbit_Const_1__port__0_reduction_dims_0), 
                sref_model_mul_eightbit_Const_1__port__0_reduction_dims_0, 
                2);
    }
    {   
        RamTensor<float>* out_tensor;
        out_tensor = new RamTensor<float>({ 1 });
        ctx.add(out_tensor, sref_model_mul_eightbit_Const_1__port__0_min_0, 1);
        ctx.push(new MinOp(), 
                { sref_model_mul_eightbit_Const_1__port__0_reshape_0, sref_model_mul_eightbit_Const_1__port__0_reduction_dims_0 },
                { sref_model_mul_eightbit_Const_1__port__0_min_0 });
        ctx.eval();
    }
    {   
        RamTensor<float>* out_tensor;
        out_tensor = new RamTensor<float>({ 1 });
        ctx.add(out_tensor, sref_model_mul_eightbit_Const_1__port__0_max_0, 1);
        ctx.push(new MaxOp(), 
                { sref_model_mul_eightbit_Const_1__port__0_reshape_0, sref_model_mul_eightbit_Const_1__port__0_reduction_dims_0 },
                { sref_model_mul_eightbit_Const_1__port__0_max_0 });
        ctx.eval();
    }
    {
        ctx.add(new RamTensor<uint8_t>(), sref_model_mul_eightbit_Const_1__port__0_quantize_0, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_mul_eightbit_Const_1__port__0_quantize_1, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_mul_eightbit_Const_1__port__0_quantize_2, 1);
        ctx.push(new QuantizeV2Op(),
                {  sref_Const_1_0,  sref_model_mul_eightbit_Const_1__port__0_min_0, sref_model_mul_eightbit_Const_1__port__0_max_0 },
                {  sref_model_mul_eightbit_Const_1__port__0_quantize_0,  sref_model_mul_eightbit_Const_1__port__0_quantize_1, sref_model_mul_eightbit_Const_1__port__0_quantize_2 });
        ctx.eval();
    }
    {    
        ctx.add(new BinaryTensor<float>({1}, inline_sref_model_mul_y_0), 
                sref_model_mul_y_0, 
                2);
    }
    {    
        ctx.add(new BinaryTensor<int>({1}, inline_sref_model_mul_eightbit_model_mul_y__port__0_reshape_dims_0), 
                sref_model_mul_eightbit_model_mul_y__port__0_reshape_dims_0, 
                1);
    }
    {
        ctx.add(new RamTensor<float>(), sref_model_mul_eightbit_model_mul_y__port__0_reshape_0, 2);
        ctx.push(new ReshapeOp(), 
                { sref_model_mul_y_0, sref_model_mul_eightbit_model_mul_y__port__0_reshape_dims_0 },
                { sref_model_mul_eightbit_model_mul_y__port__0_reshape_0 });
        ctx.eval();
    }
    {    
        ctx.add(new BinaryTensor<int>({1}, inline_sref_model_mul_eightbit_model_mul_y__port__0_reduction_dims_0), 
                sref_model_mul_eightbit_model_mul_y__port__0_reduction_dims_0, 
                2);
    }
    {   
        RamTensor<float>* out_tensor;
        out_tensor = new RamTensor<float>({ 1 });
        ctx.add(out_tensor, sref_model_mul_eightbit_model_mul_y__port__0_min_0, 1);
        ctx.push(new MinOp(), 
                { sref_model_mul_eightbit_model_mul_y__port__0_reshape_0, sref_model_mul_eightbit_model_mul_y__port__0_reduction_dims_0 },
                { sref_model_mul_eightbit_model_mul_y__port__0_min_0 });
        ctx.eval();
    }
    {   
        RamTensor<float>* out_tensor;
        out_tensor = new RamTensor<float>({ 1 });
        ctx.add(out_tensor, sref_model_mul_eightbit_model_mul_y__port__0_max_0, 1);
        ctx.push(new MaxOp(), 
                { sref_model_mul_eightbit_model_mul_y__port__0_reshape_0, sref_model_mul_eightbit_model_mul_y__port__0_reduction_dims_0 },
                { sref_model_mul_eightbit_model_mul_y__port__0_max_0 });
        ctx.eval();
    }
    {
        ctx.add(new RamTensor<uint8_t>(), sref_model_mul_eightbit_model_mul_y__port__0_quantize_0, 2);
        ctx.add(new RamTensor<float>({1}), sref_model_mul_eightbit_model_mul_y__port__0_quantize_1, 2);
        ctx.add(new RamTensor<float>({1}), sref_model_mul_eightbit_model_mul_y__port__0_quantize_2, 2);
        ctx.push(new QuantizeV2Op(),
                {  sref_model_mul_y_0,  sref_model_mul_eightbit_model_mul_y__port__0_min_0, sref_model_mul_eightbit_model_mul_y__port__0_max_0 },
                {  sref_model_mul_eightbit_model_mul_y__port__0_quantize_0,  sref_model_mul_eightbit_model_mul_y__port__0_quantize_1, sref_model_mul_eightbit_model_mul_y__port__0_quantize_2 });
        ctx.eval();
    }
    {
        ctx.add(new RamTensor<int>(), sref_model_mul_eightbit_0, 2);
        ctx.add(new RamTensor<float>({1}), sref_model_mul_eightbit_1, 2);
        ctx.add(new RamTensor<float>({1}), sref_model_mul_eightbit_2, 2);
        ctx.push(new QuantizedMulOp<uint8_t, uint8_t, int>(), 
                { sref_model_mul_eightbit_Const_1__port__0_quantize_0, sref_model_mul_eightbit_Const_1__port__0_quantize_1, sref_model_mul_eightbit_Const_1__port__0_quantize_2, sref_model_mul_eightbit_model_mul_y__port__0_quantize_0, sref_model_mul_eightbit_model_mul_y__port__0_quantize_1,  sref_model_mul_eightbit_model_mul_y__port__0_quantize_2 },
                { sref_model_mul_eightbit_0, sref_model_mul_eightbit_1,  sref_model_mul_eightbit_2 });
        ctx.eval();
    }
    {
        ctx.add(new RamTensor<float>({1}), sref_model_mul_eightbit_requant_range_0, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_mul_eightbit_requant_range_1, 1);
        ctx.push(new Requantization_RangeOp(),
                { sref_model_mul_eightbit_0, sref_model_mul_eightbit_1, sref_model_mul_eightbit_2 },
                { sref_model_mul_eightbit_requant_range_0, sref_model_mul_eightbit_requant_range_1 });
        ctx.eval();
    }
    {   
        ctx.add(new RamTensor<uint8_t>(), sref_model_mul_eightbit_requantize_0, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_mul_eightbit_requantize_1, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_mul_eightbit_requantize_2, 1);
        ctx.push(new RequantizeOp(),
                { sref_model_mul_eightbit_0, sref_model_mul_eightbit_1, sref_model_mul_eightbit_2, sref_model_mul_eightbit_requant_range_0, sref_model_mul_eightbit_requant_range_1 },
                { sref_model_mul_eightbit_requantize_0, sref_model_mul_eightbit_requantize_1, sref_model_mul_eightbit_requantize_2 });
        ctx.eval();
    }
    {    
        ctx.add(new BinaryTensor<int>({4}, inline_sref_model_Reshape_shape_0), 
                sref_model_Reshape_shape_0, 
                1);
    }
    {
        ctx.add(new RamTensor<uint8_t>(), sref_model_Reshape_eightbit_0, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_Reshape_eightbit_1, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_Reshape_eightbit_2, 1);
        ctx.push(new QuantizedReshapeOp(),
                { sref_model_mul_eightbit_requantize_0, sref_model_Reshape_shape_0, sref_model_mul_eightbit_requantize_1, sref_model_mul_eightbit_requantize_2 },
                { sref_model_Reshape_eightbit_0, sref_model_Reshape_eightbit_1, sref_model_Reshape_eightbit_2 });
        ctx.eval();
    }
    {
        ctx.add(new RamTensor<uint8_t>(), sref_model_max_pooling2d_MaxPool_eightbit_0, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_max_pooling2d_MaxPool_eightbit_1, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_max_pooling2d_MaxPool_eightbit_2, 1);

        ctx.push(new QuantizedMaxPoolingOp<uint8_t>(3, 3, 3, 3, VALID),
                { sref_model_Reshape_eightbit_0, sref_model_Reshape_eightbit_1, sref_model_Reshape_eightbit_2 }, 
                { sref_model_max_pooling2d_MaxPool_eightbit_0, sref_model_max_pooling2d_MaxPool_eightbit_1,  sref_model_max_pooling2d_MaxPool_eightbit_2 });


        ctx.eval();
    }
    {    
        ctx.add(new BinaryTensor<float>({5,5,1,22}, inline_sref_model_stochastic_conv2_mu_0), 
                sref_model_stochastic_conv2_mu_0, 
                1);
    }
    {    
        ctx.add(new BinaryTensor<float>({1}, inline_sref_model_stochastic_conv2d__channel__pruning_weights_quant_min_0), 
                sref_model_stochastic_conv2d__channel__pruning_weights_quant_min_0, 
                4);
    }
    {    
        ctx.add(new BinaryTensor<float>({1}, inline_sref_model_stochastic_conv2d__channel__pruning_weights_quant_max_0), 
                sref_model_stochastic_conv2d__channel__pruning_weights_quant_max_0, 
                6);
    }
    {
        ctx.add(new RamTensor<int>(), sref_model_stochastic_conv2d__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_quantize_0, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_conv2d__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_quantize_1, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_conv2d__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_quantize_2, 1);
        ctx.push(new QuantizeV2Op(),
                {  sref_model_stochastic_conv2_mu_0,  sref_model_stochastic_conv2d__channel__pruning_weights_quant_min_0, sref_model_stochastic_conv2d__channel__pruning_weights_quant_max_0 },
                {  sref_model_stochastic_conv2d__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_quantize_0,  sref_model_stochastic_conv2d__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_quantize_1, sref_model_stochastic_conv2d__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_quantize_2 });
        ctx.eval();
    }
    {   
        ctx.add(new RamTensor<uint8_t>(), sref_model_stochastic_conv2d__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_requantize_0, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_conv2d__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_requantize_1, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_conv2d__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_requantize_2, 1);
        ctx.push(new RequantizeOp(),
                { sref_model_stochastic_conv2d__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_quantize_0, sref_model_stochastic_conv2d__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_quantize_1, sref_model_stochastic_conv2d__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_quantize_2, sref_model_stochastic_conv2d__channel__pruning_weights_quant_min_0, sref_model_stochastic_conv2d__channel__pruning_weights_quant_max_0 },
                { sref_model_stochastic_conv2d__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_requantize_0, sref_model_stochastic_conv2d__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_requantize_1, sref_model_stochastic_conv2d__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_requantize_2 });
        ctx.eval();
    }
    {
        ctx.add(new RamTensor<int>(), sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_0, 2);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_1, 2);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_2, 2);
        ctx.push(new QntConvOp<uint8_t, uint8_t, int>({ 1, 1, 1, 1 }, VALID),
                { sref_model_max_pooling2d_MaxPool_eightbit_0, sref_model_stochastic_conv2d__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_requantize_0, sref_model_max_pooling2d_MaxPool_eightbit_1, sref_model_max_pooling2d_MaxPool_eightbit_2, sref_model_stochastic_conv2d__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_requantize_1, sref_model_stochastic_conv2d__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_requantize_2 },
                { sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_0, sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_1, sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_2 });
        ctx.eval();
    }
    {
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_requant_range_0, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_requant_range_1, 1);
        ctx.push(new Requantization_RangeOp(),
                { sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_0, sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_1, sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_2 },
                { sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_requant_range_0, sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_requant_range_1 });
        ctx.eval();
    }
    {   
        ctx.add(new RamTensor<uint8_t>(), sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_requantize_0, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_requantize_1, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_requantize_2, 1);
        ctx.push(new RequantizeOp(),
                { sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_0, sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_1, sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_2, sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_requant_range_0, sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_requant_range_1 },
                { sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_requantize_0, sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_requantize_1, sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_requantize_2 });
        ctx.eval();
    }
    {    
        ctx.add(new BinaryTensor<float>({22}, inline_sref_model_stochastic_conv2_mu_bias_0), 
                sref_model_stochastic_conv2_mu_bias_0, 
                2);
    }
    {    
        ctx.add(new BinaryTensor<int>({1}, inline_sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_reshape_dims_0), 
                sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_reshape_dims_0, 
                1);
    }
    {
        ctx.add(new RamTensor<float>(), sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_reshape_0, 2);
        ctx.push(new ReshapeOp(), 
                { sref_model_stochastic_conv2_mu_bias_0, sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_reshape_dims_0 },
                { sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_reshape_0 });
        ctx.eval();
    }
    {    
        ctx.add(new BinaryTensor<int>({1}, inline_sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_reduction_dims_0), 
                sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_reduction_dims_0, 
                2);
    }
    {   
        RamTensor<float>* out_tensor;
        out_tensor = new RamTensor<float>({ 1 });
        ctx.add(out_tensor, sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_min_0, 1);
        ctx.push(new MinOp(), 
                { sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_reshape_0, sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_reduction_dims_0 },
                { sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_min_0 });
        ctx.eval();
    }
    {   
        RamTensor<float>* out_tensor;
        out_tensor = new RamTensor<float>({ 1 });
        ctx.add(out_tensor, sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_max_0, 1);
        ctx.push(new MaxOp(), 
                { sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_reshape_0, sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_reduction_dims_0 },
                { sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_max_0 });
        ctx.eval();
    }
    {
        ctx.add(new RamTensor<uint8_t>(), sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_quantize_0, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_quantize_1, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_quantize_2, 1);
        ctx.push(new QuantizeV2Op(),
                {  sref_model_stochastic_conv2_mu_bias_0,  sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_min_0, sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_max_0 },
                {  sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_quantize_0,  sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_quantize_1, sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_quantize_2 });
        ctx.eval();
    }
    {
        ctx.add(new RamTensor<int>(), sref_model_stochastic_conv2d__channel__pruning_add_eightbit_0, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_conv2d__channel__pruning_add_eightbit_1, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_conv2d__channel__pruning_add_eightbit_2, 1);
        ctx.push(new QuantizedAddOp<uint8_t, uint8_t, int>(), 
                { sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_requantize_0, sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_requantize_1, sref_model_stochastic_conv2d__channel__pruning_Conv2D_eightbit_requantize_2, sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_quantize_0, sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_quantize_1,  sref_model_stochastic_conv2d__channel__pruning_add_eightbit_model_stochastic_conv2_mu_bias__port__0_quantize_2 },
                { sref_model_stochastic_conv2d__channel__pruning_add_eightbit_0, sref_model_stochastic_conv2d__channel__pruning_add_eightbit_1,  sref_model_stochastic_conv2d__channel__pruning_add_eightbit_2 });
        ctx.eval();
    }
    {    
        ctx.add(new BinaryTensor<float>({1}, inline_sref_model_stochastic_conv2d__channel__pruning_act_quant_min_0), 
                sref_model_stochastic_conv2d__channel__pruning_act_quant_min_0, 
                2);
    }
    {   
        ctx.add(new RamTensor<uint8_t>(), sref_model_stochastic_conv2d__channel__pruning_act_quant_FakeQuantWithMinMaxVars_hoisted_eightbit_requantize_0, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_conv2d__channel__pruning_act_quant_FakeQuantWithMinMaxVars_hoisted_eightbit_requantize_1, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_conv2d__channel__pruning_act_quant_FakeQuantWithMinMaxVars_hoisted_eightbit_requantize_2, 1);
        ctx.push(new RequantizeOp(),
                { sref_model_stochastic_conv2d__channel__pruning_add_eightbit_0, sref_model_stochastic_conv2d__channel__pruning_add_eightbit_1, sref_model_stochastic_conv2d__channel__pruning_add_eightbit_2, sref_model_stochastic_conv2d__channel__pruning_act_quant_min_0, sref_model_stochastic_conv2d__channel__pruning_weights_quant_max_0 },
                { sref_model_stochastic_conv2d__channel__pruning_act_quant_FakeQuantWithMinMaxVars_hoisted_eightbit_requantize_0, sref_model_stochastic_conv2d__channel__pruning_act_quant_FakeQuantWithMinMaxVars_hoisted_eightbit_requantize_1, sref_model_stochastic_conv2d__channel__pruning_act_quant_FakeQuantWithMinMaxVars_hoisted_eightbit_requantize_2 });
        ctx.eval();
    }
    {
        ctx.add(new RamTensor<uint8_t>(), sref_model_stochastic_conv2d__channel__pruning_act_quant_FakeQuantWithMinMaxVars_eightbit_0, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_conv2d__channel__pruning_act_quant_FakeQuantWithMinMaxVars_eightbit_1, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_conv2d__channel__pruning_act_quant_FakeQuantWithMinMaxVars_eightbit_2, 1);
        ctx.push(new QuantizedReluOp<uint8_t, float, uint8_t>(), 
                { sref_model_stochastic_conv2d__channel__pruning_act_quant_FakeQuantWithMinMaxVars_hoisted_eightbit_requantize_0, sref_model_stochastic_conv2d__channel__pruning_act_quant_FakeQuantWithMinMaxVars_hoisted_eightbit_requantize_1, sref_model_stochastic_conv2d__channel__pruning_act_quant_FakeQuantWithMinMaxVars_hoisted_eightbit_requantize_2 },
                { sref_model_stochastic_conv2d__channel__pruning_act_quant_FakeQuantWithMinMaxVars_eightbit_0, sref_model_stochastic_conv2d__channel__pruning_act_quant_FakeQuantWithMinMaxVars_eightbit_1, sref_model_stochastic_conv2d__channel__pruning_act_quant_FakeQuantWithMinMaxVars_eightbit_2 });
        ctx.eval();
    }
    {    
        ctx.add(new BinaryTensor<int>({2}, inline_sref_model_Reshape_1_shape_0), 
                sref_model_Reshape_1_shape_0, 
                1);
    }
    {
        ctx.add(new RamTensor<uint8_t>(), sref_model_Reshape_1_eightbit_0, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_Reshape_1_eightbit_1, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_Reshape_1_eightbit_2, 1);
        ctx.push(new QuantizedReshapeOp(),
                { sref_model_stochastic_conv2d__channel__pruning_act_quant_FakeQuantWithMinMaxVars_eightbit_0, sref_model_Reshape_1_shape_0, sref_model_stochastic_conv2d__channel__pruning_act_quant_FakeQuantWithMinMaxVars_eightbit_1, sref_model_stochastic_conv2d__channel__pruning_act_quant_FakeQuantWithMinMaxVars_eightbit_2 },
                { sref_model_Reshape_1_eightbit_0, sref_model_Reshape_1_eightbit_1, sref_model_Reshape_1_eightbit_2 });
        ctx.eval();
    }
    {
        ctx.add(new RamTensor<float>(), sref_model_Reshape_1_0, 1);
        ctx.push(new DequantizeOp(), 
                { sref_model_Reshape_1_eightbit_0, sref_model_Reshape_1_eightbit_1, sref_model_Reshape_1_eightbit_2 },
                { sref_model_Reshape_1_0 });
        ctx.eval();
    }
    {    
        ctx.add(new BinaryTensor<int>({122}, inline_sref_model_GatherV2_indices_0), 
                sref_model_GatherV2_indices_0, 
                1);
    }
    {    
        ctx.add(new BinaryTensor<int>({1}, inline_sref_model_GatherV2_axis_0), 
                sref_model_GatherV2_axis_0, 
                1);
    }
    {
        ctx.add(new RamTensor<float>(), sref_model_GatherV2_0, 2);
        ctx.push(new GatherOp<float>(),
                { sref_model_Reshape_1_0, sref_model_GatherV2_indices_0, sref_model_GatherV2_axis_0 }, 
                { sref_model_GatherV2_0 });
        ctx.eval();
    }
    {    
        ctx.add(new BinaryTensor<int>({1}, inline_sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_reshape_dims_0), 
                sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_reshape_dims_0, 
                1);
    }
    {
        ctx.add(new RamTensor<float>(), sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_reshape_0, 2);
        ctx.push(new ReshapeOp(), 
                { sref_model_GatherV2_0, sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_reshape_dims_0 },
                { sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_reshape_0 });
        ctx.eval();
    }
    {    
        ctx.add(new BinaryTensor<int>({1}, inline_sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_reduction_dims_0), 
                sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_reduction_dims_0, 
                2);
    }
    {   
        RamTensor<float>* out_tensor;
        out_tensor = new RamTensor<float>({ 1 });
        ctx.add(out_tensor, sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_min_0, 1);
        ctx.push(new MinOp(), 
                { sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_reshape_0, sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_reduction_dims_0 },
                { sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_min_0 });
        ctx.eval();
    }
    {   
        RamTensor<float>* out_tensor;
        out_tensor = new RamTensor<float>({ 1 });
        ctx.add(out_tensor, sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_max_0, 1);
        ctx.push(new MaxOp(), 
                { sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_reshape_0, sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_reduction_dims_0 },
                { sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_max_0 });
        ctx.eval();
    }
    {
        ctx.add(new RamTensor<uint8_t>(), sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_quantize_0, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_quantize_1, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_quantize_2, 1);
        ctx.push(new QuantizeV2Op(),
                {  sref_model_GatherV2_0,  sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_min_0, sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_max_0 },
                {  sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_quantize_0,  sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_quantize_1, sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_quantize_2 });
        ctx.eval();
    }
    {    
        ctx.add(new BinaryTensor<uint8_t>({122,10}, inline_sref_model_stochastic_dense_mu_quantized_const_0), 
                sref_model_stochastic_dense_mu_quantized_const_0, 
                1);
    }
    {    
        ctx.add(new BinaryTensor<float>({1}, inline_sref_model_stochastic_dense_mu_quantized_min_0), 
                sref_model_stochastic_dense_mu_quantized_min_0, 
                1);
    }
    {    
        ctx.add(new BinaryTensor<float>({1}, inline_sref_model_stochastic_dense_mu_quantized_max_0), 
                sref_model_stochastic_dense_mu_quantized_max_0, 
                1);
    }
    {
        ctx.add(new RamTensor<float>(), sref_model_stochastic_dense_mu_0, 1);
        ctx.push(new DequantizeOp(), 
                { sref_model_stochastic_dense_mu_quantized_const_0, sref_model_stochastic_dense_mu_quantized_min_0, sref_model_stochastic_dense_mu_quantized_max_0 },
                { sref_model_stochastic_dense_mu_0 });
        ctx.eval();
    }
    {
        ctx.add(new RamTensor<int>(), sref_model_stochastic_dense__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_quantize_0, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_dense__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_quantize_1, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_dense__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_quantize_2, 1);
        ctx.push(new QuantizeV2Op(),
                {  sref_model_stochastic_dense_mu_0,  sref_model_stochastic_conv2d__channel__pruning_weights_quant_min_0, sref_model_stochastic_conv2d__channel__pruning_weights_quant_max_0 },
                {  sref_model_stochastic_dense__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_quantize_0,  sref_model_stochastic_dense__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_quantize_1, sref_model_stochastic_dense__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_quantize_2 });
        ctx.eval();
    }
    {   
        ctx.add(new RamTensor<uint8_t>(), sref_model_stochastic_dense__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_requantize_0, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_dense__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_requantize_1, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_dense__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_requantize_2, 1);
        ctx.push(new RequantizeOp(),
                { sref_model_stochastic_dense__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_quantize_0, sref_model_stochastic_dense__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_quantize_1, sref_model_stochastic_dense__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_quantize_2, sref_model_stochastic_conv2d__channel__pruning_weights_quant_min_0, sref_model_stochastic_conv2d__channel__pruning_weights_quant_max_0 },
                { sref_model_stochastic_dense__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_requantize_0, sref_model_stochastic_dense__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_requantize_1, sref_model_stochastic_dense__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_requantize_2 });
        ctx.eval();
    }
    {
        ctx.add(new RamTensor<int>(), sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_0, 2);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_1, 2);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_2, 2);
        ctx.push(new QntMatMulOp<uint8_t, uint8_t, int>(), 
                { sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_quantize_0, sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_quantize_1, sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_model_GatherV2__port__0_quantize_2, sref_model_stochastic_dense__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_requantize_0, sref_model_stochastic_dense__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_requantize_1,  sref_model_stochastic_dense__channel__pruning_weights_quant_FakeQuantWithMinMaxVars_eightbit_requantize_2 },
                { sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_0, sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_1,  sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_2 });
        ctx.eval();
    }
    printf("Here BOY\n");
    {
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_requant_range_0, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_requant_range_1, 1);
        ctx.push(new Requantization_RangeOp(),
                { sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_0, sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_1, sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_2 },
                { sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_requant_range_0, sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_requant_range_1 });
        ctx.eval();
    }
    {   
        ctx.add(new RamTensor<uint8_t>(), sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_requantize_0, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_requantize_1, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_requantize_2, 1);
        ctx.push(new RequantizeOp(),
                { sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_0, sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_1, sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_2, sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_requant_range_0, sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_requant_range_1 },
                { sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_requantize_0, sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_requantize_1, sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_requantize_2 });
        ctx.eval();
    }
    {    
        ctx.add(new BinaryTensor<float>({10}, inline_sref_model_stochastic_dense_mu_bias_0), 
                sref_model_stochastic_dense_mu_bias_0, 
                2);
    }
    {    
        ctx.add(new BinaryTensor<int>({1}, inline_sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_reshape_dims_0), 
                sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_reshape_dims_0, 
                1);
    }
    {
        ctx.add(new RamTensor<float>(), sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_reshape_0, 2);
        ctx.push(new ReshapeOp(), 
                { sref_model_stochastic_dense_mu_bias_0, sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_reshape_dims_0 },
                { sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_reshape_0 });
        ctx.eval();
    }
    {    
        ctx.add(new BinaryTensor<int>({1}, inline_sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_reduction_dims_0), 
                sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_reduction_dims_0, 
                2);
    }
    {   
        RamTensor<float>* out_tensor;
        out_tensor = new RamTensor<float>({ 1 });
        ctx.add(out_tensor, sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_min_0, 1);
        ctx.push(new MinOp(), 
                { sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_reshape_0, sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_reduction_dims_0 },
                { sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_min_0 });
        ctx.eval();
    }
    {   
        RamTensor<float>* out_tensor;
        out_tensor = new RamTensor<float>({ 1 });
        ctx.add(out_tensor, sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_max_0, 1);
        ctx.push(new MaxOp(), 
                { sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_reshape_0, sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_reduction_dims_0 },
                { sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_max_0 });
        ctx.eval();
    }
    {
        ctx.add(new RamTensor<uint8_t>(), sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_quantize_0, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_quantize_1, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_quantize_2, 1);
        ctx.push(new QuantizeV2Op(),
                {  sref_model_stochastic_dense_mu_bias_0,  sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_min_0, sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_max_0 },
                {  sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_quantize_0,  sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_quantize_1, sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_quantize_2 });
        ctx.eval();
    }
    {
        ctx.add(new RamTensor<int>(), sref_model_stochastic_dense__channel__pruning_add_eightbit_0, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_dense__channel__pruning_add_eightbit_1, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_dense__channel__pruning_add_eightbit_2, 1);
        ctx.push(new QuantizedAddOp<uint8_t, uint8_t, int>(), 
                { sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_requantize_0, sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_requantize_1, sref_model_stochastic_dense__channel__pruning_MatMul_eightbit_requantize_2, sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_quantize_0, sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_quantize_1,  sref_model_stochastic_dense__channel__pruning_add_eightbit_model_stochastic_dense_mu_bias__port__0_quantize_2 },
                { sref_model_stochastic_dense__channel__pruning_add_eightbit_0, sref_model_stochastic_dense__channel__pruning_add_eightbit_1,  sref_model_stochastic_dense__channel__pruning_add_eightbit_2 });
        ctx.eval();
    }
    {   
        ctx.add(new RamTensor<uint8_t>(), sref_model_stochastic_dense__channel__pruning_act_quant_FakeQuantWithMinMaxVars_eightbit_requantize_0, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_dense__channel__pruning_act_quant_FakeQuantWithMinMaxVars_eightbit_requantize_1, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_stochastic_dense__channel__pruning_act_quant_FakeQuantWithMinMaxVars_eightbit_requantize_2, 1);
        ctx.push(new RequantizeOp(),
                { sref_model_stochastic_dense__channel__pruning_add_eightbit_0, sref_model_stochastic_dense__channel__pruning_add_eightbit_1, sref_model_stochastic_dense__channel__pruning_add_eightbit_2, sref_model_stochastic_conv2d__channel__pruning_act_quant_min_0, sref_model_stochastic_conv2d__channel__pruning_weights_quant_max_0 },
                { sref_model_stochastic_dense__channel__pruning_act_quant_FakeQuantWithMinMaxVars_eightbit_requantize_0, sref_model_stochastic_dense__channel__pruning_act_quant_FakeQuantWithMinMaxVars_eightbit_requantize_1, sref_model_stochastic_dense__channel__pruning_act_quant_FakeQuantWithMinMaxVars_eightbit_requantize_2 });
        ctx.eval();
    }
    {
        ctx.add(new RamTensor<int>(), sref_model_mul_3_eightbit_0, 2);
        ctx.add(new RamTensor<float>({1}), sref_model_mul_3_eightbit_1, 2);
        ctx.add(new RamTensor<float>({1}), sref_model_mul_3_eightbit_2, 2);
        ctx.push(new QuantizedMulOp<uint8_t, uint8_t, int>(), 
                { sref_model_stochastic_dense__channel__pruning_act_quant_FakeQuantWithMinMaxVars_eightbit_requantize_0, sref_model_stochastic_dense__channel__pruning_act_quant_FakeQuantWithMinMaxVars_eightbit_requantize_1, sref_model_stochastic_dense__channel__pruning_act_quant_FakeQuantWithMinMaxVars_eightbit_requantize_2, sref_model_mul_eightbit_model_mul_y__port__0_quantize_0, sref_model_mul_eightbit_model_mul_y__port__0_quantize_1,  sref_model_mul_eightbit_model_mul_y__port__0_quantize_2 },
                { sref_model_mul_3_eightbit_0, sref_model_mul_3_eightbit_1,  sref_model_mul_3_eightbit_2 });
        ctx.eval();
    }
    {
        ctx.add(new RamTensor<float>({1}), sref_model_mul_3_eightbit_requant_range_0, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_mul_3_eightbit_requant_range_1, 1);
        ctx.push(new Requantization_RangeOp(),
                { sref_model_mul_3_eightbit_0, sref_model_mul_3_eightbit_1, sref_model_mul_3_eightbit_2 },
                { sref_model_mul_3_eightbit_requant_range_0, sref_model_mul_3_eightbit_requant_range_1 });
        ctx.eval();
    }
    {   
        ctx.add(new RamTensor<uint8_t>(), sref_model_mul_3_eightbit_requantize_0, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_mul_3_eightbit_requantize_1, 1);
        ctx.add(new RamTensor<float>({1}), sref_model_mul_3_eightbit_requantize_2, 1);
        ctx.push(new RequantizeOp(),
                { sref_model_mul_3_eightbit_0, sref_model_mul_3_eightbit_1, sref_model_mul_3_eightbit_2, sref_model_mul_3_eightbit_requant_range_0, sref_model_mul_3_eightbit_requant_range_1 },
                { sref_model_mul_3_eightbit_requantize_0, sref_model_mul_3_eightbit_requantize_1, sref_model_mul_3_eightbit_requantize_2 });
        ctx.eval();
    }
    {
        ctx.add(new RamTensor<float>(), sref_model_mul_3_0);
        ctx.push(new DequantizeOp(), 
                { sref_model_mul_3_eightbit_requantize_0, sref_model_mul_3_eightbit_requantize_1, sref_model_mul_3_eightbit_requantize_2 },
                { sref_model_mul_3_0 });
    }
}
